{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c1cf6e",
   "metadata": {},
   "source": [
    "# Truncated distributions\n",
    "\n",
    "This tutorial will cover how to implement your own\n",
    "truncated distribution in NumPyro.\n",
    "It is assumed that you're already familiar with the basics of NumPyro.\n",
    "To get the most out of this tutorial, you'll need some background in probability.\n",
    "\n",
    "**Contents**\n",
    "* [1. What is a truncated distribution?](#1)\n",
    "* [2. Sampling from a truncated distribution](#2)\n",
    "* [3. Recap of NumPyro distributions](#3)\n",
    "* [4. Building your own truncanted distributions](#4)\n",
    "    * [4.1 Right-truncated normal](#4.1)\n",
    "    * [4.2 Left-truncated Poisson](#4.2)\n",
    "* [5. Ready-to-use truncated distributions available in NumPyro](#5)\n",
    "* [6. References](#6)\n",
    "\n",
    "\n",
    "## What is a truncated distribution? <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "The **support** of a probability distribution is the set of values\n",
    "in the domain with **non-zero probability**. For example, the\n",
    "support of the normal distribution is the whole real line (even if\n",
    "the density gets very small as we move away from the mean, technically\n",
    "speaking, it is never quite zero). The support of the uniform distribution,\n",
    "as coded in `jax.random.uniform` with the default arguments, is the interval $\\left[0, 1)\\right.$, because any\n",
    "value outside of that interval has zero probability. The support of the Poisson distribution is the set of non-negative integers, etc.\n",
    "\n",
    "**Truncating** a distribution makes its support smaller\n",
    "so that any value outside our desired domain has zero probability. In practice, this can be useful\n",
    "for modelling situations in which certain biases are introduced during data collection.\n",
    "For example, some physical detectors only get triggered when the signal is above some\n",
    "minimum threshold, or sometimes the detectors fail if the signal exceeds a certain value.\n",
    "As a result, the **observed values are constrained to be within a limited range of values**,\n",
    "even though the true signal does not have the same constraints.\n",
    "See, for example, section 3.1 of _Information Theory and Learning Algorithms_ by David Mackay.\n",
    "Naively, if $S$ is the support of the original density $p_Y(y)$, then by truncating to a new support\n",
    "$T\\subset S$ we are effectively defining a new random variable $Z$ for which the density is\n",
    "\n",
    "\\begin{equation}\n",
    "  p_Z(z) \\propto\n",
    "    \\begin{cases}\n",
    "      p_Y(z) & \\text{if $z$ is in $T$}\\\\\n",
    "      0 & \\text{if $z$ is outside $T$}\\\\\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "\n",
    "The reason for writing a $\\propto$ (proportional to) sign instead of a strict equation is that,\n",
    "defined in the above way, the resulting function does not integrate to $1$ and so it cannot be strictly considered a probability density. To make it into a probability density **we need to re-distribute the truncated mass**\n",
    "among the part of the distribution that remains. To do this, we simply re-weight every point by the same constant:\n",
    "\n",
    "\\begin{equation}\n",
    "  p_Z(z) =\n",
    "    \\begin{cases}\n",
    "      \\frac{1}{M}p_Y(z) & \\text{if $z$ is in $T$}\\\\\n",
    "      0 & \\text{if $z$ is outside $T$}\\\\\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "\n",
    "where $M = \\int_T p_Y(y)\\mathrm{d}y$.\n",
    "\n",
    "In practice, the truncation is often one-sided. This means that if, for example, the support before truncation is the interval $(a, b)$, then the support after truncation is of the form $(a, c)$ or $(c, b)$, with $a < c < b$. The figure below illustrates a right-sided truncation.\n",
    "\n",
    "<img src=\"https://i.ibb.co/x2fhd0y/truncated-normal.png\" alt=\"drawing\" width=\"900\"/>\n",
    "\n",
    "The original distribution (left side) is truncated at the vertical dotted line. The truncated mass (orange region) is redistributed in the new support (right side) so that the total area under the curve remains equal to 1 even after truncation. Though there could be other forms of re-weighting the truncated distribution, this method\n",
    "ensures that the density ratio between any two points, $p(a)/p(b)$ remains the same before and after\n",
    "the reweighting is done (as long as the points are inside the new support, of course).\n",
    "For this same reason, if the truncation point is known and we are going to do inference using MCMC, the normalization constant $M$ can simply be dropped.\n",
    "\n",
    "**Note**: Truncated data is different from _censored_ data. Censoring also hides values that are outside some desired support but, contrary to truncated data, we know when a value has been censored. The typical example is the household scale which does not report values above 300 pounds. Censored data will not be covered in this tutorial.\n",
    "\n",
    "## Sampling from a truncated distribution <a class=\"anchor\" id=\"2\"></a>\n",
    "\n",
    "Usually, we already have a sampler for the pre-truncated distribution (e.g. `np.random.normal`).\n",
    "So, a seemingly simple way of generating samples from the truncated distribution would be to\n",
    "sample from the original distribution, and then discard the samples that are outside the \n",
    "desired support. For example, if we wanted samples from a normal distribution truncated to the\n",
    "support $(-\\infty, 1)$, we'd simply do:\n",
    "\n",
    "```python\n",
    "upper = 1\n",
    "samples = np.random.normal(size=1000)\n",
    "truncated_samples = samples[samples < upper]\n",
    "```\n",
    "\n",
    "This is called **_rejection sampling_ but it is not very efficient**.\n",
    "If the region we truncated had a sufficiently high probability mass, then we'd be discarding a lot of samples and it might be a while before we accumulate sufficient samples for the truncated distribution. For example, the above snippet would only result in $\\sim 840$ truncated samples even though we initially drew $1000$. This can easily get a lot worse for other combinations of parameters.\n",
    "A **more efficient** approach is to use a method known as [inverse transform sampling](https://en.wikipedia.org/wiki/Inverse_transform_sampling).\n",
    "In this method, we first sample from a uniform distribution in (0, 1) and then transform those samples with the inverse cumulative distribution of our truncated distribution.\n",
    "This method ensures that no samples are wasted in the process, though it does have the slight complication that\n",
    "**we need to calculate the inverse CDF (ICDF)** of our truncated distribution. This might sound too complicated at first but, with a bit of algebra, we can often calculate the truncated ICDF in terms of the untruncated ICDF. The untruncated ICDF for many distributions is already available.\n",
    "\n",
    "Before we move on to the examples, let's do a quick recap of NumPyro distributions.\n",
    "\n",
    "## A quick recap of NumPyro distributions <a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "A NumPyro distribution should subclass `Distribution` and implement a few basic ingredients:\n",
    "\n",
    "**Class attributes:**\n",
    "The class attributes serve a few different purposes. Here we will mainly care about two:\n",
    "1. `arg_constraints`: Impose some requirements on the parameters of the distribution. Errors are raised at instantiation time if the parameters passed do not satisfy the constraints.\n",
    "2. `support`: It is used in some inference algorithms like MCMC and SVI with auto-guides, where we need to perform the algorithm in the unconstrained space. Knowing the support, we can automatically reparametrize things under the hood.\n",
    "\n",
    "We'll explain other class attributes as we go.\n",
    "\n",
    "**The `__init__` method:**\n",
    "This is where we define the parameters of the distribution.\n",
    "We also use `jax` and `lax` to promote the parameters to shapes that are valid for broadcasting.\n",
    "The `__init__` method of the parent class is also required because that's where the validation of our parameters is done.\n",
    "\n",
    "**The `log_prob` method:**\n",
    "Implementing the `log_prob` method ensures that we can do inference. As the name suggests, this method returns the logarithm of the density evaluated at the argument.\n",
    "\n",
    "\n",
    "**The `sample` method:**\n",
    "This method is used for drawing independent samples from our distribution. It is particularly useful for doing prior checks.\n",
    "\n",
    "\n",
    "The place-holder code for any of our implementations can be written as\n",
    "```python\n",
    "class MyDistribution(Distribution):\n",
    "    # class attributes\n",
    "    arg_constraints = {}\n",
    "    support = None\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def log_prob(self, value):\n",
    "        pass\n",
    "    \n",
    "    def sample(self, key, sample_shape=()):\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5e01d",
   "metadata": {},
   "source": [
    "## Examples <a class=\"anchor\" id=\"4\"></a>\n",
    "Let's now move on to concrete examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03ed3317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omarfsosa/.pyenv/versions/3.8.10/envs/numpyro/lib/python3.8/site-packages/jax/_src/lib/__init__.py:32: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from jax import lax, random\n",
    "from jax.scipy.special import ndtr, ndtri\n",
    "from jax.scipy.stats import poisson, norm\n",
    "from numpyro.distributions import (\n",
    "    constraints,\n",
    "    Distribution,\n",
    "    FoldedDistribution,\n",
    "    SoftLaplace,\n",
    "    StudentT,\n",
    "    TruncatedDistribution,\n",
    "    TruncatedNormal,\n",
    ")\n",
    "from numpyro.distributions.util import promote_shapes\n",
    "from numpyro.infer import DiscreteHMCGibbs, MCMC, NUTS, Predictive\n",
    "from scipy.stats import poisson as sp_poisson\n",
    "\n",
    "numpyro.enable_x64()\n",
    "RNG = random.PRNGKey(0)\n",
    "MCMC_KWARGS = dict(\n",
    "    num_warmup=2000,\n",
    "    num_samples=2000,\n",
    "    num_chains=4,\n",
    "    chain_method=\"sequential\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7923078f",
   "metadata": {},
   "source": [
    "### Example: Right-truncated normal <a class=\"anchor\" id=\"4.1\"></a>\n",
    "\n",
    "We are going to modify a normal distribution so that its new support is\n",
    "of the form `(-inf, high)`, with `high` a real number. We'll call our distribution `RightTruncatedNormal`. Let's write the skeleton code and then proceed to fill in the blanks.\n",
    "\n",
    "```python\n",
    "class RightTruncatedNormal(Distribution):\n",
    "    # <class attributes>\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def log_prob(self, value):\n",
    "        pass\n",
    "    \n",
    "    def sample(self, key, sample_shape=()):\n",
    "        pass\n",
    "```\n",
    "    \n",
    "\n",
    "#### Class attributes\n",
    "Remember that a non-truncated normal distribution is specified in NumPyro by two parameters, `loc` and `scale`,\n",
    "which correspond to the mean and standard deviation.\n",
    "Looking at the [source code](https://github.com/pyro-ppl/numpyro/blob/0664c2d2dd1eb5f41ea6a0bcef91e5fa2a417ce5/numpyro/distributions/continuous.py#L1337) for the `Normal` distribution we see the following lines:\n",
    "\n",
    "```python\n",
    "arg_constraints = {\"loc\": constraints.real, \"scale\": constraints.positive}\n",
    "support = constraints.real\n",
    "reparametrized_params = [\"loc\", \"scale\"]\n",
    "```\n",
    "The `reparametrized_params` is used to determine if a distribution is reparameterizable. Reparametrizing is used to deal with complicated posterior geometries that make sampling very slow or biased. See [this tutorial](https://pyro.ai/examples/svi_part_iii.html#Tricky-Case:-Non-reparameterizable-Random-Variables) if you're interested.\n",
    "\n",
    "We must adapt these attributes to our case by including the `\"high\"` parameter, but there are two issues we need to deal with:\n",
    "1. `constraints.real` is a bit too restrictive. We'd like `jnp.inf` to be a valid value for `high` (equivalent to no truncation), but at the moment infinity is not a valid real number. We deal with this situation by defining our own constraint. The source code for `constraints.real` is easy to imitate:\n",
    "\n",
    "```python\n",
    "class _RightExtendedReal(constraints.Constraint):\n",
    "    \"\"\"\n",
    "    Any number in the interval (-inf, inf].\n",
    "    \"\"\"\n",
    "    def __call__(self, x):\n",
    "        return (x == x) & (x != float(\"-inf\"))\n",
    "    \n",
    "    def feasible_like(self, prototype):\n",
    "        return jnp.zeros_like(prototype)\n",
    "\n",
    "right_extended_real = _RightExtendedReal()\n",
    "```\n",
    "\n",
    "2. `support` can no longer be a class attribute as it will depend on the value of `high`. So instead we implement it as a dependent property.\n",
    "\n",
    "Our distribution then looks as follows:\n",
    "```python\n",
    "class RightTruncatedNormal(Distribution):\n",
    "    arg_constraints = {\n",
    "        \"loc\": constraints.real,\n",
    "        \"scale\": constraints.positive,\n",
    "        \"high\": right_extended_real,\n",
    "    }\n",
    "    reparametrized_params = [\"loc\", \"scale\", \"high\"]\n",
    "    \n",
    "    # ...\n",
    "    \n",
    "    @constraints.dependent_property\n",
    "    def support(self):\n",
    "        return constraints.lower_than(self.high)\n",
    "```\n",
    "\n",
    "#### The `__init__` method\n",
    "Once again we take inspiration from the [source code](https://github.com/pyro-ppl/numpyro/blob/0664c2d2dd1eb5f41ea6a0bcef91e5fa2a417ce5/numpyro/distributions/continuous.py#L1342) for the normal distribution. The key point is the use of `lax` and `jax` to check the shapes of the arguments passed and make sure that such shapes are consistent for broadcasting. We follow the same pattern for our use case -- all we need to do is include the `high` parameter.\n",
    "\n",
    "In the source implementation of `Normal`, both parameters `loc` and `scale` are given defaults so that one recovers a standard normal distribution if no arguments are specified. In the same spirit, we choose `float(\"inf\")` as a default for our `high` which would be equivalent to no truncation.\n",
    "\n",
    "```python\n",
    "# ...\n",
    "    def __init__(self, loc=0.0, scale=1.0, high=float(\"inf\"), validate_args=None):\n",
    "        batch_shape = lax.broadcast_shapes(\n",
    "            jnp.shape(loc),\n",
    "            jnp.shape(scale),\n",
    "            jnp.shape(high),\n",
    "        )\n",
    "        self.loc, self.scale, self.high = promote_shapes(loc, scale, high)\n",
    "        super().__init__(batch_shape, validate_args=validate_args)\n",
    "# ...\n",
    "```\n",
    "\n",
    "#### The `log_prob` method\n",
    "For a truncated distribution, the log density is given by\n",
    "\n",
    "\\begin{equation}\n",
    "  \\log p_Z(z) =\n",
    "    \\begin{cases}\n",
    "      \\log p_Y(z) - \\log M & \\text{if $z$ is in $T$}\\\\\n",
    "      -\\infty & \\text{if $z$ is outside $T$}\\\\\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "\n",
    "where, again, $p_Z$ is the density of the truncated distribution, $p_Y$ is the density before truncation, and $M = \\int_T p_Y(y)\\mathrm{d}y$. For the specific case of truncating the normal distribution to the interval `(-inf, high)`, the constant $M$ is equal to the cumulative density evaluated at the truncation point. We can easily implement this log-density method because `jax.scipy.stats` already has a `norm` module that we can use.\n",
    "\n",
    "```python\n",
    "# ...\n",
    "    def log_prob(self, value):\n",
    "        log_m = norm.logcdf(self.high, self.loc, self.scale)\n",
    "        log_p = norm.logpdf(value, self.loc, self.scale)\n",
    "        return jnp.where(value < self.high, log_p - log_m, -jnp.inf)\n",
    "# ...\n",
    "```\n",
    "\n",
    "#### The `sample` method\n",
    "\n",
    "To implement the sample method using inverse-transform sampling, we need to also implement the inverse cumulative distribution function. For this, we can use the `ndtri` function that lives inside `jax.scipy.special`. This function returns the inverse cdf for the standard normal distribution. We can do a bit of algebra to obtain the inverse cdf of the truncated, non-standard normal. First recall that if $X\\sim Normal(0, 1)$ and $Y = \\mu + \\sigma X$, then $Y\\sim Normal(\\mu, \\sigma)$. Then if $Z$ is the truncated $Y$, its cumulative density is given by:\n",
    "\n",
    "\\begin{align}\n",
    "F_Z(y) &= \\int_{-\\infty}^{y}p_Z(r)dr\\newline\n",
    "       &= \\frac{1}{M}\\int_{-\\infty}^{y}p_Y(s)ds \\quad\\text{if $y < high$} \\newline\n",
    "       &= \\frac{1}{M}F_Y(y)\n",
    "\\end{align}\n",
    "\n",
    "And so its inverse is\n",
    "\n",
    "\\begin{align}\n",
    "F_Z^{-1}(u) = \\left(\\frac{1}{M}F_Y\\right)^{-1}(u)\n",
    "            = F_Y^{-1}(M u)\n",
    "            = F_{\\mu + \\sigma X}^{-1}(Mu)\n",
    "            = \\mu + \\sigma F_X^{-1}(Mu)\n",
    "\\end{align}\n",
    "\n",
    "The translation of the above math into code is\n",
    "\n",
    "```python\n",
    "# ...\n",
    "    def sample(self, key, sample_shape=()):\n",
    "        shape = sample_shape + self.batch_shape\n",
    "        minval = jnp.finfo(jnp.result_type(float)).tiny\n",
    "        u = random.uniform(key, shape, minval=minval)\n",
    "        return self.icdf(u)\n",
    "\n",
    "\n",
    "    def icdf(self, u):\n",
    "        m = norm.cdf(self.high, self.loc, self.scale)\n",
    "        return self.loc + self.scale * ndtri(m * u)\n",
    "```\n",
    "\n",
    "With everything in place, the final implementation is as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef4c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _RightExtendedReal(constraints.Constraint):\n",
    "    \"\"\"\n",
    "    Any number in the interval (-inf, inf].\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return (x == x) & (x != float(\"-inf\"))\n",
    "\n",
    "    def feasible_like(self, prototype):\n",
    "        return jnp.zeros_like(prototype)\n",
    "\n",
    "\n",
    "right_extended_real = _RightExtendedReal()\n",
    "\n",
    "\n",
    "class RightTruncatedNormal(Distribution):\n",
    "    \"\"\"\n",
    "    A truncated Normal distribution.\n",
    "    :param numpy.ndarray loc: location parameter of the untruncated normal\n",
    "    :param numpy.ndarray scale: scale parameter of the untruncated normal\n",
    "    :param numpy.ndarray high: point at which the truncation happens\n",
    "    \"\"\"\n",
    "\n",
    "    arg_constraints = {\n",
    "        \"loc\": constraints.real,\n",
    "        \"scale\": constraints.positive,\n",
    "        \"high\": right_extended_real,\n",
    "    }\n",
    "    reparametrized_params = [\"loc\", \"scale\", \"high\"]\n",
    "\n",
    "    def __init__(self, loc=0.0, scale=1.0, high=float(\"inf\"), validate_args=True):\n",
    "        batch_shape = lax.broadcast_shapes(\n",
    "            jnp.shape(loc),\n",
    "            jnp.shape(scale),\n",
    "            jnp.shape(high),\n",
    "        )\n",
    "        self.loc, self.scale, self.high = promote_shapes(loc, scale, high)\n",
    "        super().__init__(batch_shape, validate_args=validate_args)\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        log_m = norm.logcdf(self.high, self.loc, self.scale)\n",
    "        log_p = norm.logpdf(value, self.loc, self.scale)\n",
    "        return jnp.where(value < self.high, log_p - log_m, -jnp.inf)\n",
    "\n",
    "    def sample(self, key, sample_shape=()):\n",
    "        shape = sample_shape + self.batch_shape\n",
    "        minval = jnp.finfo(jnp.result_type(float)).tiny\n",
    "        u = random.uniform(key, shape, minval=minval)\n",
    "        return self.icdf(u)\n",
    "\n",
    "    def icdf(self, u):\n",
    "        m = norm.cdf(self.high, self.loc, self.scale)\n",
    "        return self.loc + self.scale * ndtri(m * u)\n",
    "\n",
    "    @constraints.dependent_property\n",
    "    def support(self):\n",
    "        return constraints.less_than(self.high)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4175f2e",
   "metadata": {},
   "source": [
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3792cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_normal_model(num_observations, x=None):\n",
    "    loc = numpyro.sample(\"loc\", dist.Normal())\n",
    "    scale = numpyro.sample(\"scale\", dist.LogNormal())\n",
    "    high = numpyro.sample(\"high\", dist.Normal())\n",
    "    with numpyro.plate(\"observations\", num_observations):\n",
    "        numpyro.sample(\"x\", RightTruncatedNormal(loc, scale, high), obs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc1b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_observations = 250\n",
    "num_prior_samples = 100\n",
    "prior = Predictive(truncated_normal_model, num_samples=num_prior_samples)\n",
    "prior_samples = prior(RNG, num_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff52c5",
   "metadata": {},
   "source": [
    "To test our inference, we run mcmc against some synthetic data.\n",
    "We select any random sample from the prior as the ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9483511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_idx = 0\n",
    "true_loc = prior_samples[\"loc\"][true_idx]\n",
    "true_scale = prior_samples[\"scale\"][true_idx]\n",
    "true_high = prior_samples[\"high\"][true_idx]\n",
    "true_x = prior_samples[\"x\"][true_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e471c6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(true_x, bins=20)\n",
    "plt.axvline(true_high, linestyle=\":\", color=\"k\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235cd8f4",
   "metadata": {},
   "source": [
    "Run MCMC and check the estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3a979e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:01<00:00, 2426.62it/s, 3 steps of size 1.74e-01. acc. prob=0.73]\n",
      "sample: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 17030.70it/s, 11 steps of size 1.26e-01. acc. prob=0.79]\n",
      "sample: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 12800.69it/s, 26 steps of size 1.75e-02. acc. prob=0.93]\n",
      "sample: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 16592.33it/s, 5 steps of size 1.03e-01. acc. prob=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "      high      0.08      0.00      0.08      0.08      0.08    736.20      1.00\n",
      "       loc      1.35      0.54      1.28      0.45      2.18    128.85      1.03\n",
      "     scale      0.93      0.13      0.92      0.73      1.15    142.55      1.02\n",
      "\n",
      "Number of divergences: 6496\n"
     ]
    }
   ],
   "source": [
    "mcmc = MCMC(NUTS(truncated_normal_model), **MCMC_KWARGS)\n",
    "mcmc.run(RNG, num_observations, true_x)\n",
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57f0535",
   "metadata": {},
   "source": [
    "Compare estimates against the ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dedf4f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True high : 0.08\n",
      "True loc  : 1.09\n",
      "True scale: 0.84\n"
     ]
    }
   ],
   "source": [
    "print(f\"True high : {true_high:3.2f}\")\n",
    "print(f\"True loc  : {true_loc:3.2f}\")\n",
    "print(f\"True scale: {true_scale:3.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552e4b15",
   "metadata": {},
   "source": [
    "Note that, even though we can recover good estimates for the true values,\n",
    "we had a very high number of divergences. These divergences happen because\n",
    "introducing the truncation makes the log-density not smooth (the NUTS\n",
    "algorithm relies on the differentiability of the posterior). If you need to\n",
    "infer the truncation point, make sure to be extra careful and do additional\n",
    "checks on your inferences!\n",
    "\n",
    "The results are more reliable when the truncation point is already known:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd377bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_known_high = numpyro.handlers.condition(\n",
    "    truncated_normal_model, {\"high\": true_high}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22cf5cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:01<00:00, 2734.95it/s, 17 steps of size 2.13e-01. acc. prob=0.92]\n",
      "sample: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 19170.76it/s, 11 steps of size 1.77e-01. acc. prob=0.94]\n",
      "sample: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 18432.83it/s, 3 steps of size 1.82e-01. acc. prob=0.94]\n",
      "sample: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 18333.99it/s, 23 steps of size 1.75e-01. acc. prob=0.95]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       loc      1.41      0.56      1.34      0.53      2.25   1285.24      1.00\n",
      "     scale      0.95      0.13      0.94      0.74      1.15   1308.89      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mcmc = MCMC(NUTS(model_with_known_high), **MCMC_KWARGS)\n",
    "mcmc.run(RNG, num_observations, true_x)\n",
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5454e89",
   "metadata": {},
   "source": [
    "**A quick note about making predictions**\n",
    "\n",
    "In practice, we usually want to understand how the data\n",
    "would look like without the truncation. To do that in NumPyro,\n",
    "there is no need of writing a separate model, we can simply\n",
    "rely on the `condition` handler to remove the truncation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a3c6831",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_truncation = numpyro.handlers.condition(\n",
    "    model_with_known_high,\n",
    "    {\"high\": float(\"inf\")},\n",
    ")\n",
    "posterior = Predictive(\n",
    "    model_without_truncation,\n",
    "    posterior_samples=mcmc.get_samples(),\n",
    ")\n",
    "posterior_samples = posterior(RNG, num_observations=2270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6139d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thin the samples for a faster histogram\n",
    "posterior_example = posterior_samples[\"x\"].ravel()[::1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28877060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].hist(posterior_example, label=\"Untruncated posterior\", bins=20, density=True)\n",
    "axes[0].axvline(true_high, linestyle=\":\", color=\"k\", label=\"Truncation point\")\n",
    "axes[0].set_title(\"Untruncated posterior\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(\n",
    "    posterior_example[posterior_example < true_high],\n",
    "    label=\"Tail of untruncated posterior\",\n",
    "    bins=20,\n",
    "    density=True,\n",
    ")\n",
    "axes[1].hist(true_x, label=\"Observed, truncated data\", density=True, alpha=0.5)\n",
    "axes[1].axvline(true_high, linestyle=\":\", color=\"k\", label=\"Truncation point\")\n",
    "axes[1].set_title(\"Comparison to observed data\")\n",
    "axes[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed9169a",
   "metadata": {},
   "source": [
    "### Example: Left-truncated Poisson <a class=\"anchor\" id=\"4.2\"></a>\n",
    "\n",
    "We now implement a left-truncated Poisson distribution.\n",
    "Note that a right-truncated Poisson could be reformulated as a particular\n",
    "case of a categorical distribution, so we focus on the less trivial case.\n",
    "\n",
    "#### Class attributes.\n",
    "For a truncated Poisson we need two parameters, the `rate` of the original Poisson\n",
    "distribution and a `low` parameter to indicate the truncation point.\n",
    "As this is a discrete distribution, we need to clarify whether or not the truncation point is included\n",
    "in the support. In this tutorial, we'll take the convention that the truncation point `low`\n",
    "_is_ part of the support.\n",
    "\n",
    "The `low` parameter has to be given a 'non-negative integer' constraint. As it is a discrete parameter, it will not be possible to do inference for this parameter using `NUTS`. This is likely not a problem since the truncation point is often known in advance. However, if we really must infer the `low` parameter, it is possible to do so with `DiscreteHMCGibbs` though one is limited to using priors with enumerate support.\n",
    "\n",
    "Like in the case of the truncated normal, the support of this distribution will be defined as a property and not as a class attribute because it depends on the specific value of the `low` parameter.\n",
    "```python\n",
    "class LeftTruncatedPoisson:\n",
    "    arg_constraints = {\n",
    "        \"low\": constraints.nonnegative_integer,\n",
    "        \"rate\": constraints.positive,\n",
    "    }\n",
    "    \n",
    "    # ... \n",
    "    @constraints.dependent_property(is_discrete=True)\n",
    "    def support(self):\n",
    "        return constraints.integer_greater_than(self.low - 1)\n",
    "```\n",
    "\n",
    "The `is_discrete` argument passed in the `dependent_property` decorator is used to tell the inference algorithms which variables are discrete latent variables.\n",
    "\n",
    "#### The `__init__` method\n",
    "Here we just follow the same pattern as in the previous example.\n",
    "```python\n",
    "    # ...\n",
    "    def __init__(self, rate=1.0, low=0, validate_args=None):\n",
    "        batch_shape = lax.broadcast_shapes(\n",
    "            jnp.shape(low), jnp.shape(rate)\n",
    "        )\n",
    "        self.low, self.rate = promote_shapes(low, rate)\n",
    "        super().__init__(batch_shape, validate_args=validate_args)\n",
    "    # ...\n",
    "```\n",
    "\n",
    "\n",
    "#### The `log_prob` method\n",
    "The logic is very similar to the truncated normal case. But this time we are truncating on the left, so the correct normalization is the complementary cumulative density:\n",
    "\n",
    "\\begin{align}\n",
    "M = \\sum_{n=L}^{\\infty} p_Y(n) = 1 - \\sum_{n=0}^{L - 1} p_Y(n) = 1 - F_Y(L - 1)\n",
    "\\end{align}\n",
    "\n",
    "For the code, we can rely on the `poisson` module that lives inside `jax.scipy.stats`.\n",
    "\n",
    "```python\n",
    "    # ...\n",
    "    def log_prob(self, value):\n",
    "        m = 1 - poisson.cdf(self.low - 1, self.rate)\n",
    "        log_p = poisson.logpmf(value, self.rate)\n",
    "        return jnp.where(value >= self.low, log_p - jnp.log(m), -jnp.inf)\n",
    "    # ...\n",
    "```\n",
    "#### The `sample` method.\n",
    "Inverse-transform sampling also works for discrete distributions. The \"inverse\" cdf of a discrete distribution being defined as:\n",
    "\n",
    "\\begin{align}\n",
    "F^{-1}(u) = \\max\\left\\{n\\in \\mathbb{N} \\rvert F(n) \\lt u\\right\\}\n",
    "\\end{align}\n",
    "\n",
    "Or, in plain English, $F^{-1}(u)$ is the highest number for which the cumulative density is less than $u$.\n",
    "However, there's currently no implementation of $F^{-1}$ for the Poisson distribution in Jax (at least, at the moment of writing this tutorial). We have to rely on our own implementation. Fortunately, we can take advantage of the discrete nature of the distribution and easily implement a \"brute-force\" version that will work for most cases. The brute force approach consists of simply scanning all non-negative integers in order, one by one, until the value of the cumulative density exceeds the argument $u$. The implicit requirement is that we need a way to evaluate the cumulative density for the truncated distribution, but we can calculate that:\n",
    "\n",
    "\\begin{align}\n",
    "F_Z(z) &= \\sum_{n=0}^z p_z(n)\\newline\n",
    "       &= \\frac{1}{M}\\sum_{n=L}^z p_Y(n)\\quad \\text{assuming $z >= L$}\\newline\n",
    "       &= \\frac{1}{M}\\left(\\sum_{n=0}^z p_Y(n) - \\sum_{n=0}^{L-1}p_Y(n)\\right)\\newline\n",
    "       &= \\frac{1}{M}\\left(F_Y(z) - F_Y (L-1)\\right)\n",
    "\\end{align}\n",
    "\n",
    "And, of course, the value of $F_Z(z)$ is equal to zero if $z < L$.\n",
    "(As in the previous example, we are using $Y$ to denote the original, un-truncated variable, and we are using $Z$ to denote the truncated variable)\n",
    "\n",
    "```python\n",
    "    # ...\n",
    "    def sample(self, key, sample_shape=()):\n",
    "        shape = sample_shape + self.batch_shape\n",
    "        minval = jnp.finfo(jnp.result_type(float)).tiny\n",
    "        u = random.uniform(key, shape, minval=minval)\n",
    "        return self.icdf(u)\n",
    "\n",
    "    @partial(jax.vmap, in_axes=(None, 0))\n",
    "    def icdf(self, u):\n",
    "        result = lax.while_loop(\n",
    "            lambda n: self.cdf(n, self.rate, self.low) < u,\n",
    "            lambda n: n + 1,\n",
    "            init_val=self.low,\n",
    "        )\n",
    "        return result.astype(jnp.result_type(int))\n",
    "\n",
    "    def cdf(self, value):\n",
    "        m = 1 - poisson.cdf(self.low - 1, self.rate)\n",
    "        f = poisson.cdf(value, self.rate) - poisson.cdf(self.low - 1, self.rate)\n",
    "        return jnp.where(k >= self.low, f / m, 0)\n",
    "```\n",
    "\n",
    "A few warnings with respect to the above implementation:\n",
    "* Even with double precision, if `rate` is much less than `low`, the above code will not work. Due to numerical limitations, one obtains that `poisson.cdf(low - 1, rate)` is equal (or very close) to `1.0`. This makes it impossible to re-weight the distribution accurately because the normalization constant would be `0.0`.\n",
    "* The brute-force `icdf` is of course very slow, particularly when `rate` is high. If you need faster sampling, one option would be to rely on a faster search algorithm. For example:\n",
    "```python\n",
    "def icdf_faster(self, u):\n",
    "    num_bins = 200 # Choose a reasonably large value\n",
    "    bins = jnp.arange(num_bins)\n",
    "    cdf = self.cdf(bins)\n",
    "    indices = jnp.searchsorted(cdf, u)\n",
    "    return bins[indices]\n",
    "```\n",
    "The obvious limitation here is that the number of bins has to be fixed a priori (jax does not allow for dynamically sized arrays). Another option would be to rely on an _approximate_ implementation, as proposed in [this article](https://people.maths.ox.ac.uk/gilesm/codes/poissinv/paper.pdf).\n",
    "* Yet another alternative for the `icdf` is to rely on `scipy`'s implementation and make use of Jax's `host_callback` module. This feature allows you to use Python functions without having to code them in `Jax`. This means that we can simply make use of `scipy`'s implementation of the Poisson ICDF! From the last equation, we can write the _truncated_ icdf as:\n",
    "\\begin{align}\n",
    "F_Z^{-1}(u) = F_Y^{-1}(Mu + F_Y(L-1))\n",
    "\\end{align}\n",
    "    And in python:\n",
    "\n",
    "```python\n",
    "    def scipy_truncated_poisson_icdf(args): # Note: all arguments are passed inside a tuple\n",
    "        rate, low, u = args\n",
    "        rate = np.asarray(rate)\n",
    "        low = np.asarray(low)\n",
    "        u = np.asarray(u)\n",
    "        density = sp_poisson(rate)\n",
    "        low_cdf = density.cdf(low - 1)\n",
    "        normalizer = 1.0 - low_cdf\n",
    "        x = normalizer * u + low_cdf\n",
    "        return density.ppf(x)\n",
    "```\n",
    "In principle, it wouldn't be possible to use the above function in our NumPyro distribution because it is not  coded in Jax. The `jax.experimental.host_callback.call` function solves precisely that problem. The code below shows you how to use it, but keep in mind that this is currently an experimental feature so you should expect changes to the module. If you're interested, the docstring for the `host_callback` module has a detailed explanation.\n",
    "\n",
    "```python\n",
    "    # ...\n",
    "    def icdf_scipy(self, u):\n",
    "        result_shape = jax.ShapeDtypeStruct(\n",
    "            u.shape,\n",
    "            jnp.result_type(float) # int type not currently supported\n",
    "        )\n",
    "        result = jax.experimental.host_callback.call(\n",
    "            scipy_truncated_poisson_icdf,\n",
    "            (self.rate, self.low, u),\n",
    "            result_shape=result_shape\n",
    "        )\n",
    "        return result.astype(jnp.result_type(int))\n",
    "    # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ca08a9",
   "metadata": {},
   "source": [
    "Putting it all together, the implementation is as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13a86497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scipy_truncated_poisson_icdf(args):  # Note: all arguments are passed inside a tuple\n",
    "    rate, low, u = args\n",
    "    rate = np.asarray(rate)\n",
    "    low = np.asarray(low)\n",
    "    u = np.asarray(u)\n",
    "    density = sp_poisson(rate)\n",
    "    low_cdf = density.cdf(low - 1)\n",
    "    normalizer = 1.0 - low_cdf\n",
    "    x = normalizer * u + low_cdf\n",
    "    return density.ppf(x)\n",
    "\n",
    "\n",
    "class LeftTruncatedPoisson(Distribution):\n",
    "    \"\"\"\n",
    "    A truncated Poisson distribution.\n",
    "    :param numpy.ndarray low: lower bound at which truncation happens\n",
    "    :param numpy.ndarray rate: rate of the Poisson distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    arg_constraints = {\n",
    "        \"low\": constraints.nonnegative_integer,\n",
    "        \"rate\": constraints.positive,\n",
    "    }\n",
    "\n",
    "    def __init__(self, rate=1.0, low=0, validate_args=None):\n",
    "        batch_shape = lax.broadcast_shapes(jnp.shape(low), jnp.shape(rate))\n",
    "        self.low, self.rate = promote_shapes(low, rate)\n",
    "        super().__init__(batch_shape, validate_args=validate_args)\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        m = 1 - poisson.cdf(self.low - 1, self.rate)\n",
    "        log_p = poisson.logpmf(value, self.rate)\n",
    "        return jnp.where(value >= self.low, log_p - jnp.log(m), -jnp.inf)\n",
    "\n",
    "    def sample(self, key, sample_shape=()):\n",
    "        shape = sample_shape + self.batch_shape\n",
    "        float_type = jnp.result_type(float)\n",
    "        minval = jnp.finfo(float_type).tiny\n",
    "        u = random.uniform(key, shape, minval=minval)\n",
    "        # return self.icdf(u)        # Brute force\n",
    "        # return self.icdf_faster(u) # For faster sampling.\n",
    "        return self.icdf_scipy(u)  # Using `host_callback`\n",
    "\n",
    "    @partial(jax.vmap, in_axes=(None, 0))\n",
    "    def icdf(self, u):\n",
    "        result = lax.while_loop(\n",
    "            lambda n: self.cdf(n) < u,\n",
    "            lambda n: n + 1,\n",
    "            init_val=self.low,\n",
    "        )\n",
    "        return result.astype(jnp.result_type(int))\n",
    "\n",
    "    def icdf_faster(self, u):\n",
    "        num_bins = 200  # Choose a reasonably large value\n",
    "        bins = jnp.arange(num_bins)\n",
    "        cdf = self.cdf(bins)\n",
    "        indices = jnp.searchsorted(cdf, u)\n",
    "        return bins[indices]\n",
    "\n",
    "    def icdf_scipy(self, u):\n",
    "        result_shape = jax.ShapeDtypeStruct(u.shape, jnp.result_type(float))\n",
    "        result = jax.experimental.host_callback.call(\n",
    "            scipy_truncated_poisson_icdf,\n",
    "            (self.rate, self.low, u),\n",
    "            result_shape=result_shape,\n",
    "        )\n",
    "        return result.astype(jnp.result_type(int))\n",
    "\n",
    "    def cdf(self, value):\n",
    "        m = 1 - poisson.cdf(self.low - 1, self.rate)\n",
    "        f = poisson.cdf(value, self.rate) - poisson.cdf(self.low - 1, self.rate)\n",
    "        return jnp.where(value >= self.low, f / m, 0)\n",
    "\n",
    "    @constraints.dependent_property(is_discrete=True)\n",
    "    def support(self):\n",
    "        return constraints.integer_greater_than(self.low - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba41bcd9",
   "metadata": {},
   "source": [
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3356242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_distplot(samples, ax=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Utility function for plotting the samples as a barplot.\n",
    "    \"\"\"\n",
    "    x, y = jnp.unique(samples, return_counts=True)\n",
    "    y = y / sum(y)\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    ax.bar(x, y, **kwargs)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b4fd99",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5591d56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = LeftTruncatedPoisson(5, 10)\n",
    "samples = d.sample(RNG, sample_shape=(1000,))\n",
    "discrete_distplot(samples);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e21342",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6103409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_poisson_model(num_observations, x=None):\n",
    "    low = numpyro.sample(\"low\", dist.Categorical(0.2 * jnp.ones((5,))))\n",
    "    rate = numpyro.sample(\"rate\", dist.LogNormal(1, 1))\n",
    "    with numpyro.plate(\"observations\", num_observations):\n",
    "        numpyro.sample(\"x\", LeftTruncatedPoisson(rate, low), obs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c28722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- prior samples\n",
    "num_observations = 1000\n",
    "num_prior_samples = 100\n",
    "prior = Predictive(truncated_poisson_model, num_samples=num_prior_samples)\n",
    "prior_samples = prior(RNG, num_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c97134f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take any prior sample as the true process.\n",
    "true_idx = 4\n",
    "true_low = prior_samples[\"low\"][true_idx]\n",
    "true_rate = prior_samples[\"rate\"][true_idx]\n",
    "true_x = prior_samples[\"x\"][true_idx]\n",
    "discrete_distplot(true_x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6fdc77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the use of DiscreteHMCGibbs\n",
    "mcmc = MCMC(DiscreteHMCGibbs(NUTS(truncated_poisson_model)), **MCMC_KWARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70136785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:02<00:00, 1845.68it/s, 1 steps of size 1.00e+00. acc. prob=0.92]\n",
      "sample: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 10525.78it/s, 3 steps of size 8.36e-01. acc. prob=0.94]\n",
      "sample: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 10640.65it/s, 3 steps of size 8.65e-01. acc. prob=0.94]\n",
      "sample: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 10811.05it/s, 3 steps of size 1.02e+00. acc. prob=0.92]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       low      4.00      0.00      4.00      4.00      4.00       nan       nan\n",
      "      rate      8.61      0.10      8.61      8.45      8.78   2615.67      1.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mcmc.run(RNG, num_observations, true_x)\n",
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be5ea6",
   "metadata": {},
   "source": [
    "We also see some \"ugly\" diagnostics here simply because the `low` parameter is estimated with\n",
    "no uncertainty. As before, one needs to be extra careful when estimating the truncation point.\n",
    "If the truncation point is known is best to provide it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b93149d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_known_low = numpyro.handlers.condition(\n",
    "    truncated_poisson_model, {\"low\": true_low}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0340ac",
   "metadata": {},
   "source": [
    "And note we can use NUTS directly because there's no need to infer any discrete parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcbcc6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = MCMC(\n",
    "    NUTS(model_with_known_low),\n",
    "    **MCMC_KWARGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3c6f6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:01<00:00, 2766.60it/s, 1 steps of size 1.18e+00. acc. prob=0.88]\n",
      "sample: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 11799.00it/s, 3 steps of size 1.02e+00. acc. prob=0.92]\n",
      "sample: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 12015.84it/s, 3 steps of size 1.13e+00. acc. prob=0.90]\n",
      "sample: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 11813.17it/s, 3 steps of size 9.07e-01. acc. prob=0.94]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "      rate      8.61      0.10      8.61      8.44      8.77   2827.71      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mcmc.run(RNG, num_observations, true_x)\n",
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ca027",
   "metadata": {},
   "source": [
    "## Built-in truncated distributions <a class=\"anchor\" id=\"5\"></a>\n",
    "\n",
    "The above sections show how to construct your own truncated distribution, but you don't have to reinvent the wheel. NumPyro has a bunch of truncated distributions already implemented in the `numpyro.distributions` module.\n",
    "\n",
    "For example, for the `right_truncated_model` we can simply use the `TruncatedNormal` distribution.\n",
    "Note, however, that NumPyro's implementation requires you to provide the truncation point(s),\n",
    "and **it(they) should be provided as a keyword argument(s)** (`loc` and `scale` remain valid positional arguments).\n",
    "\n",
    "This is how we would use it in a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20e6a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_normal_model(num_observations, high, x=None):\n",
    "    loc = numpyro.sample(\"loc\", dist.Normal())\n",
    "    scale = numpyro.sample(\"scale\", dist.LogNormal())\n",
    "    with numpyro.plate(\"observations\", num_observations):\n",
    "        numpyro.sample(\"x\", TruncatedNormal(loc, scale, high=high), obs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519360ec",
   "metadata": {},
   "source": [
    "And we quickly repeat our workflow to check that everything is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71aeac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:01<00:00, 3010.43it/s, 11 steps of size 3.12e-01. acc. prob=0.91]\n",
      "sample: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 20964.79it/s, 9 steps of size 3.02e-01. acc. prob=0.92]\n",
      "sample: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 20822.28it/s, 3 steps of size 3.39e-01. acc. prob=0.93]\n",
      "sample: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 20820.65it/s, 11 steps of size 2.93e-01. acc. prob=0.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       loc      0.98      0.18      0.95      0.70      1.25   1250.09      1.00\n",
      "     scale      0.81      0.09      0.80      0.67      0.94   1302.44      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "True loc  : 1.1\n",
      "True scale: 0.84\n"
     ]
    }
   ],
   "source": [
    "# --- sample from the prior\n",
    "high = 1.2\n",
    "num_observations = 250\n",
    "num_prior_samples = 100\n",
    "prior = Predictive(truncated_normal_model, num_samples=num_prior_samples)\n",
    "prior_samples = prior(RNG, num_observations, high)\n",
    "\n",
    "# -- select an arbitrary prior sample as true data\n",
    "true_idx = 0\n",
    "true_loc = prior_samples[\"loc\"][true_idx]\n",
    "true_scale = prior_samples[\"scale\"][true_idx]\n",
    "true_x = prior_samples[\"x\"][true_idx]\n",
    "\n",
    "# --- do posterior inference with NUTS\n",
    "mcmc = MCMC(NUTS(truncated_normal_model), **MCMC_KWARGS)\n",
    "mcmc.run(RNG, num_observations, high, true_x)\n",
    "\n",
    "# --- Check estimates and diagnostics\n",
    "mcmc.print_summary()\n",
    "\n",
    "# --- And compare to ground truth\n",
    "print(f\"True loc  : {true_loc:3.2}\")\n",
    "print(f\"True scale: {true_scale:3.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d48fad0",
   "metadata": {},
   "source": [
    "The source code for the `TruncatedNormal` in NumPyro uses a class called\n",
    "`TruncatedDistribution` which abstracts away the logic for `sample` and `log_prob` that\n",
    "we discussed in the previous sections - though it only works for continuous variables.\n",
    "You can use this class to quickly construct other truncated distributions, the only requirement\n",
    "is that **the base distribution should have an `icdf` method**. \n",
    "\n",
    "For example, if you need a truncated `SoftLaplace` distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7271dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TruncatedSoftLaplace(\n",
    "    loc=0.0, scale=1.0, *, low=None, high=None, validate_args=None\n",
    "):\n",
    "    return TruncatedDistribution(\n",
    "        base_dist=SoftLaplace(loc, scale),\n",
    "        low=low,\n",
    "        high=high,\n",
    "        validate_args=validate_args,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "985593c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_soft_laplace_model(num_observations, high, x=None):\n",
    "    loc = numpyro.sample(\"loc\", dist.Normal())\n",
    "    scale = numpyro.sample(\"scale\", dist.LogNormal())\n",
    "    with numpyro.plate(\"obs\", num_observations):\n",
    "        numpyro.sample(\"x\", TruncatedSoftLaplace(loc, scale, high=high), obs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ff0025d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:01<00:00, 2600.83it/s, 7 steps of size 7.66e-01. acc. prob=0.92]\n",
      "sample: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 15728.89it/s, 3 steps of size 8.21e-01. acc. prob=0.91]\n",
      "sample: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 14998.51it/s, 7 steps of size 7.06e-01. acc. prob=0.93]\n",
      "sample: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 15112.65it/s, 3 steps of size 6.31e-01. acc. prob=0.94]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "       loc      0.94      0.10      0.94      0.78      1.10   3531.19      1.00\n",
      "     scale      0.83      0.07      0.82      0.72      0.94   3982.81      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "True loc  : 1.1\n",
      "True scale: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "high = 2.3\n",
    "num_observations = 200\n",
    "num_prior_samples = 100\n",
    "\n",
    "prior = Predictive(truncated_soft_laplace_model, num_samples=num_prior_samples)\n",
    "prior_samples = prior(RNG, num_observations, high)\n",
    "\n",
    "true_idx = 0\n",
    "true_x = prior_samples[\"x\"][true_idx]\n",
    "true_loc = prior_samples[\"loc\"][true_idx]\n",
    "true_scale = prior_samples[\"scale\"][true_idx]\n",
    "\n",
    "mcmc = MCMC(\n",
    "    NUTS(truncated_soft_laplace_model),\n",
    "    **MCMC_KWARGS,\n",
    ")\n",
    "\n",
    "mcmc.run(\n",
    "    RNG,\n",
    "    num_observations,\n",
    "    high,\n",
    "    true_x,\n",
    ")\n",
    "\n",
    "mcmc.print_summary()\n",
    "\n",
    "print(f\"True loc  : {true_loc:3.2}\")\n",
    "print(f\"True scale: {true_scale:3.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd150391",
   "metadata": {},
   "source": [
    "Something to keep in mind is that, if you only need to do MCMC,\n",
    "you just need to implement the `log_prob` method. This means that you\n",
    "might be able to do inference with truncated distributions even without\n",
    "the `sample` method (which would be the case if, for example, the base\n",
    "distribution you are trying to truncate does not have an `icdf` method)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c1c440",
   "metadata": {},
   "source": [
    "## Folded distributions\n",
    "\n",
    "To finish up this tutorial, we look at \"folded\" distributions.\n",
    "\n",
    "A very common situation is truncation at zero of a univariate distribution that is symmetric around zero.\n",
    "The most popular examples are the so-called \"half-normal\", \"half-student\" or \"half-cauchy\".\n",
    "This is a special, simpler kind of truncation because the normalization constant of the log-density will always\n",
    "be $1/2$. Even more, sampling can be done by simply taking the absolute value of unfolded samples (no need for inverse-transform sampling).\n",
    "\n",
    "The logic for folded distributions has already been implemented in the `FoldedDistribution` class.\n",
    "Here's how you can use it to define, for instance, a \"half-student\" distribution (`HalfNormal` and `HalfCauchy` are already available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba0cf57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HalfStudentT(df, scale=1.0):\n",
    "    return FoldedDistribution(\n",
    "        StudentT(df, 0.0, scale),  # Note: Folding is always done around zero.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00f137e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_student_model(num_observations, x=None):\n",
    "    df = numpyro.sample(\"df\", dist.Gamma(6, 2))\n",
    "    scale = numpyro.sample(\"scale\", dist.LogNormal())\n",
    "    with numpyro.plate(\"obs\", num_observations):\n",
    "        numpyro.sample(\"x\", HalfStudentT(df, scale), obs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfe28a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:01<00:00, 2419.08it/s, 7 steps of size 6.50e-01. acc. prob=0.92]\n",
      "sample: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 8934.18it/s, 3 steps of size 6.49e-01. acc. prob=0.92]\n",
      "sample: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 8568.21it/s, 7 steps of size 6.23e-01. acc. prob=0.93]\n",
      "sample: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 8530.11it/s, 7 steps of size 5.61e-01. acc. prob=0.94]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "        df      5.05      0.92      4.96      3.56      6.46   2922.51      1.00\n",
      "     scale      0.87      0.04      0.86      0.80      0.93   3141.28      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "True df   : 6.22\n",
      "True scale: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- prior sampling\n",
    "num_observations = 500\n",
    "num_prior_samples = 100\n",
    "prior = Predictive(half_student_model, num_samples=num_prior_samples)\n",
    "prior_samples = prior(RNG, num_observations)\n",
    "\n",
    "\n",
    "# --- choose any prior sample as the ground truth\n",
    "true_idx = 0\n",
    "true_df = prior_samples[\"df\"][true_idx]\n",
    "true_scale = prior_samples[\"scale\"][true_idx]\n",
    "true_x = prior_samples[\"x\"][true_idx]\n",
    "\n",
    "# --- do inference with MCMC\n",
    "mcmc = MCMC(\n",
    "    NUTS(half_student_model),\n",
    "    **MCMC_KWARGS,\n",
    ")\n",
    "mcmc.run(RNG, num_observations, true_x)\n",
    "\n",
    "# --- Check diagostics\n",
    "mcmc.print_summary()\n",
    "\n",
    "# --- Compare to ground truth:\n",
    "print(f\"True df   : {true_df:3.2f}\")\n",
    "print(f\"True scale: {true_scale:3.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecec291",
   "metadata": {},
   "source": [
    "## References and related material <a class=\"anchor\" id=\"6\"></a>\n",
    "\n",
    "- Inverse transform sampling: https://en.wikipedia.org/wiki/Inverse_transform_sampling\n",
    "- David Mackay's book on information theory: http://www.inference.org.uk/itprnn/book.pdf\n",
    "- Pyro SVI tutorial part 3: https://pyro.ai/examples/svi_part_iii.html#Tricky-Case:-Non-reparameterizable-Random-Variables\n",
    "- Paper on approximate icdf for the poisson distribution: https://people.maths.ox.ac.uk/gilesm/codes/poissinv/paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e33f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
